# `Spark UI`

## 一级入口

### `Jobs`

- 首先映入眼帘的是默认的 `Jobs` 页面，`Jobs` 页面记录着应用中涉及的 `Actions` 动作，以及与数据读取、移动有关的动作。其中，每一个 `Action` 都对应着一个 `Job`，而每一个 `Job` 都对应着一个作业。我们可以发现对于 `Jobs` 页面来说，是以 `Actions` 为粒度，记录着每个 `Action` 对应作业的执行情况。我们想要了解作业详情，也必须通过 `Description` 页面提供的二级入口链接。

### `Stages`

- 每一个作业可能包含多个 `Stage`，在 `Stages` 页面，`Spark UI` 罗列了应用中涉及的所有 `Stages`，这些 `Stages` 分属于不同的作业。要想查看哪些 `Stages` 隶属于哪个 `Job`，还需要从 `Jobs` 的 `Descriptions` 二级入口进入查看。
- `Stages` 页面，更多地是一种预览，要想查看每一个 `Stage` 的详情，同样需要从 `Description` 进入 `Stage` 详情页

### `Storage`

- `Storage` 详情页，记录着每一个分布式缓存（`RDD Cache`、`DataFrame Cache`）的细节，包括缓存级别、已缓存的分区数、缓存比例、内存大小与磁盘大小。
- `Spark` 支持的不同缓存级别，它是存储介质（内存、磁盘）、存储形式（对象、序列化字节）与副本数量的排列组合。对于 `DataFrame` 来说，默认的级别是单副本的 `Disk Memory Deserialized`

- `Cached Partitions` 与 `Fraction Cached` 分别记录着数据集成功缓存的分区数量，以及这些缓存的分区占所有分区的比例。当 `Fraction Cached` 小于 `100%` 的时候，说明分布式数据集并没有完全缓存到内存（或是磁盘），对于这种情况，我们要警惕缓存换入换出可能会带来的性能隐患。
- 基于 `Storage` 页面提供的详细信息，我们可以有的放矢地设置与内存有关的配置项，如 `spark.executor.memory`、`spark.memory.fraction`、`spark.memory.storageFraction`， 从而有针对性对 `Storage Memory` 进行调整。

### `Environment`

- 接下来，我们再来说说 `Environment`。顾名思义，`Environment` 页面记录的是各种各样的环境变量与配置项信息

- 其中有几个一级的目录，说明如下：

  | 序号 | Metrics               | 含义                                          |
  | ---- | --------------------- | --------------------------------------------- |
  | 1    | `Runtime Information` | `Java`、`Scala`版本号等信息                   |
  | 2    | `Spark Properties`    | 所有`Spark`配置项设置细节                     |
  | 3    | `Hadoop Properties`   | `Hadoop`配置项细节                            |
  | 4    | `System Properties`   | 应用提交方法(`spark-shell`或是`spark-submit`) |
  | 5    | `Classpath Entries`   | `Classpath`路径设置信息                       |

- 这 5 类信息中，`Spark Properties` 是重点，其中记录着所有在运行时生效的 `Spark`配置项设置。通过 `Spark Properties`，我们可以确认运行时的设置，与我们预期的设置是否一致，从而排除因配置项设置错误而导致的稳定性或是性能问题。

### `Executors`

- `Executors` 的主要内容如下，主要包含“`Summary`”和“`Executors`”两部分。这两部分所记录的度量指标是一致的，其中“`Executors`”以更细的粒度记录着每一个 `Executor` 的详情，而第一部分“`Summary`”是下面所有 `Executors` 度量指标的简单加和。

- | 序号 | `Metrics`                            | 含义                                        |
  | ---- | ------------------------------------ | ------------------------------------------- |
  | 1    | `RDD Blocks`                         | 原始数据集的分区数量                        |
  | 2    | `Storage Memory`                     | 用于`Cache`的内存占用                       |
  | 3    | `Disk Used`                          | 计算过程中消耗的磁盘空间                    |
  | 4    | `Cores`                              | 用于计算的`CPU`核数                         |
  | 5    | `Active/Failed/Complete/Total Tasks` | (活跃的/失败的/完成的/总共的)分布式任务数量 |
  | 6    | `Task Time(GC TIme)`                 | 任务执行时间(括号内为任务`GC`时间)          |
  | 7    | `Input`                              | 输入数据量大小                              |
  | 8    | `Shuffle Read/Write`                 | `shuffle`读写过程中消耗的数据量             |
  | 9    | `Logs / Thread Dump`                 | 日志与`Core Dump`                           |

- 不难发现，`Executors` 页面清清楚楚地记录着每一个 `Executor` 消耗的数据量，以及它们对 `CPU`、内存与磁盘等硬件资源的消耗。基于这些信息，我们可以轻松判断不同 `Executors` 之间是否存在负载不均衡的情况，进而判断应用中是否存在数据倾斜的隐患。

### `SQL`

- 当我们的应用包含 `DataFrame`、`Dataset` 或是 `SQL` 的时候，`Spark UI` 的 `SQL` 页面，就会展示相应的内容
- 并不是所有的 `sql` 操作都会产生 `Job`，对于 `show`、`use` 这种类型的操作一般是不会有 `job` 产生的，因为本身并没有出发相应的 `Action` 操作，只是获取元数据信息进行转换。
- 具体来说，一级入口页面，以 `Actions` 为单位，记录着每个 `Action` 对应的 `Spark SQL`执行计划。我们需要点击 “`Description`” 列中的超链接，才能进入到二级页面，去了解每个执行计划的详细信息。

### 一级入口总结

| 一级入口     | 重点内容                                         |
| ------------ | ------------------------------------------------ |
| `Executors`  | 不同`Executors`之间，是否存在负载倾斜            |
| `Enviroment` | `Spark Properties`配置项确认                     |
| `Storage`    | 分布式数据集的缓存级别，内存、磁盘缓存比例       |
| `SQL`        | 初步了解不同执行计划的执行时间，确实是否符合预期 |
| `Jobs`       | 初步感知不同`Jobs`的执行时间，确实是否符合预期   |
| `Stages`     | 初步认识不同`Stages`的执行时间，确实是否符合预期 |

## 二级入口

- 所谓二级入口，它指的是，通过一次超链接跳转才能访问到的页面。对于 `SQL`、`Jobs` 和 `Stages` 这 3 类入口来说，二级入口往往已经提供了足够的信息，基本覆盖了“体检报告”的全部内容。因此，尽管 `Spark UI` 也提供了少量的三级入口（需要两跳才能到达的页面），但是这些隐藏在“犄角旮旯”的三级入口，往往并不需要开发者去特别关注。

### `SQL`详情页

#### `Exchange`

- 对于每一个 `Exchange`，`Spark UI` 都提供了丰富的 `Metrics` 来刻画 `Shuffle` 的计算过程。从 `Shuffle Write` 到 `Shuffle Read`，从数据量到处理时间，应有尽有。

- | 序号 | `Metrics`                     | 含义                                                   |
  | ---- | ----------------------------- | ------------------------------------------------------ |
  | 1    | `Shuffle records written`     | `Shuffle Write`阶段写入的数据条目数量                  |
  | 2    | `Shuffle write time total`    | `Shuffle Write`阶段花费的写入时间                      |
  | 3    | `Records read`                | `Shuffle Read`阶段读取的数据条目数量                   |
  | 4    | `Local bytes read total`      | `Shuffle Read`阶段从本地节点读取的数据总量             |
  | 5    | `Fetch wait time total`       | `Shuffle Read`阶段花费在网络传输上的时间               |
  | 6    | `Remote bytes read total`     | `Shuffle Read`阶段跨网络、从远端节点读取的数据总量     |
  | 7    | `Local blocks read`           | `Shuffle Read`阶段从本地节点读取的数据块总数量         |
  | 8    | `Remote blocks read`          | `Shuffle Read`阶段跨网络、从远端节点读取的数据块总数量 |
  | 9    | `Data size total`             | 原始数据在内存中展开之后的总大小                       |
  | 10   | `Remote bytes read to disk`   | `Shuffle Read`阶段因数据块过大而直接落盘的情况         |
  | 11   | `Shuffle bytes written total` | `Shuffle`中间文件总大小                                |

#### `Sort`

- | 序号 | `Metrics`           | 含义                           |
  | ---- | ------------------- | ------------------------------ |
  | 1    | `Sort time total`   | 排序消耗的总时间               |
  | 2    | `Peak memory total` | 内存消耗峰值(集群范围内)       |
  | 3    | `Spill size total`  | 排序过程中溢出到磁盘的数据总量 |

- 可以看到，“`Peak memory total`”和“`Spill size total`”这两个数值，足以指导我们更有针对性地去设置 `spark.executor.memory`、`spark.memory.fraction`、`spark.memory.storageFraction`，从而使得 `Execution Memory` 区域得到充分的保障。

#### `Aggregate`

- 与 `Sort` 类似，衡量 `Aggregate` 的度量指标，主要记录的也是操作的内存消耗
- 对于 `Aggregate` 操作，`Spark UI` 也记录着磁盘溢出与峰值消耗，即 `Spill size` 和 `Peak memory total`。这两个数值也为内存的调整提供了依据

### `Jobs`详情页

- `Jobs` 详情页非常的简单、直观，它罗列着隶属于当前 `Job` 的所有 `Stages`。要想访问每一个 `Stage` 的执行细节，我们还需要通过

  “`Description`”的超链接做跳转。

### `Stages` 详情页

- 要访问 `Stage` 详情，我们还有另外一种选择，那就是直接从 `Stages` 一级入口进入，然后完成跳转。因此，`Stage` 详情页也归类到二级入口。
- 在所有二级入口中，`Stage` 详情页的信息量可以说是最大的。点进 `Stage` 详情页，可以看到它主要包含 3 大类信息，分别是 `Stage DAG`、`Event Timeline` 与 `Task Metrics`。
- 其中，`Task Metrics` 又分为“`Summary`”与“`Entry details`”两部分，提供不同粒度的信息汇总。而 `Task Metrics` 中记录的指标类别，还可以通过“`Show Additional Metrics`”选项进行扩展。

#### `Stage DAG`

- 首先，我们先来看最简单的 `Stage DAG`。点开蓝色的“`DAG Visualization`”按钮，我们就能获取到当前 `Stage` 的 `DAG`

#### `Event Timeline`

- `Event Timeline`，记录着分布式任务调度与执行的过程中，不同计算环节主要的时间花销。图中的每一个条带，都代表着一个分布式任务，条带由不同的颜色构成。其中不同颜色的矩形，代表不同环节的计算时间。

- | 序号 | `Metrics`                   | 颜色 | 含义                               |
  | ---- | --------------------------- | ---- | ---------------------------------- |
  | 1    | `Scheduler Delay`           | 深蓝 | 调度延迟(调度系统开销)             |
  | 2    | `Task Deserialization Time` | 红色 | 任务的反序列化时间（调度系统开销） |
  | 3    | `Shuffle Read Time`         | 橙色 | `Shuffle Read`时间开销             |
  | 4    | `Executor Compution Time`   | 绿色 | 计算时间                           |
  | 5    | `Shuffle Write Time`        | 黄色 | `Shuffle Write`时间开销            |
  | 6    | `Result Serialization Time` | 紫色 | 任务结果的序列化时间               |
  | 7    | `Getting Result Time`       | 浅蓝 | 结果收集花费的时间                 |

- 理想情况下，条带的大部分应该都是绿色的（如图中所示），也就是任务的时间消耗，大部分都是执行时间。不过，实际情况并不总是如此，比如，有些时候，蓝色的部分占比较多，或是橙色的部分占比较大。

- 在这些情况下，我们就可以结合 `Event Timeline`，来判断作业是否存在调度开销过大、或是 `Shuffle` 负载过重的问题，从而有针对性地对不同环节做调优。比方说，如果条带中深蓝的部分（`Scheduler Delay`）很多，那就说明任务的调度开销很重。这个时候，我们就需要去相应地调整 `CPU`、内存与并行度，从而减低任务的调度开销。再比如，如果条带中黄色（`Shuffle Write Time`）与橙色（`Shuffle Read Time`）的面积较大，就说明任务的 `Shuffle` 负载很重，这个时候，我们就需要考虑，有没有可能通过利用 `Broadcast Join` 来消除 `Shuffle`，从而缓解任务的 `Shuffle` 负担。

#### `Task Metrics`

- 说完 `Stage DAG` 与 `Event Timeline`，最后，我们再来说一说 `Stage` 详情页的重头戏：`Task Metrics`。之所以说它是重头戏，在于 `Task Metrics` 以不同的粒度，提供了详尽的量化指标。其中，`"Tasks"`以 `Task` 为粒度，记录着每一个分布式任务的执行细节，而`"Summary Metrics"`则是对于所有 `Tasks` 执行细节的统计汇总。我们先来看看粗粒度的 `Summary Metrics`，然后再去展开细粒度的 `Tasks`。

##### `Summary Metrics`

- 首先，我们点开`Show Additional Metrics`按钮，勾选“`Select All`”，让所有的度量指标都生效。可以看到，`"Select All"`生效之后，`Spark UI` 打印出了所有的执行细节。

- | 序号 | `Metrics`                      | 含义                                             |
  | ---- | ------------------------------ | ------------------------------------------------ |
  | 1    | `Duration`                     | `Task`执行时间                                   |
  | 2    | `GC Time`                      | 任务执行过程中，`Java GC`时间                    |
  | 3    | `Peak Execution Memory`        | 内存峰值消耗                                     |
  | 4    | `Spill(Memory)`                | 溢出数据的内存占用                               |
  | 5    | `Spill(Disk)`                  | 溢出数据的磁盘占用                               |
  | 6    | `Shuffle Read Size / Records`  | `Shuffle Read`阶段读取的数据量与条目数量         |
  | 7    | `Shuffle Read Blocked Time`    | `Shuffle Read`阶段的网络延迟                     |
  | 8    | `Shuffle Remote Reads`         | `Shuffle Read`阶段跨节点、从远端节点拉取的数据量 |
  | 9    | `Shuffle Write Size / Records` | `Shuffle Write`阶段写入的数据量与条目数量        |
  | 10   | `Shuffle Write Time`           | `Shuffle Write`阶段花费的写入时间                |

##### `Task`

- 介绍完粗粒度的 `Summary Metrics`，接下来，我们再来说说细粒度的“`Tasks`”。实际上，`Tasks` 的不少指标，与 `Summary` 是高度重合的，

- | 序号 | `Metrics`        | 含义         |
  | ---- | ---------------- | ------------ |
  | 1    | `Locality level` | 本地性级别   |
  | 2    | `Logs`           | 执行日志     |
  | 3    | `Errors`         | 执行错误细节 |

  
