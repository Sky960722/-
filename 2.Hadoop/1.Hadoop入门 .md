# Hadoop（入门）

## Hadoop概述

1. Hadoop是什么

   1. Hadoop是一个由Apache基金会所开发的分布式系统基础架构

   1. 主要解决，海量数据的存储和海量数据的分析计算问题

   1. 广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈

2. Hadoop三大发行版本

   - Apache、Cloudera、Hortonworks
     - Apache 版本最原始（最基础）的版本
     - Cloudera 内部集成了很多大数据框架
     - CDP 整合了Hortonworks和Cloudera

3. Apache Hadoop下载地址

   - 官网地址：https://hadoop.apache.org/
   - 下载地址：https://hadoop.apache.org/releases.html

4. Hadoop优势

   - 高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失
   - 高扩展性：在集群间分配任何数据，可方便地扩展数以千计的节点
   - 高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度
   - 高容错性：能够自动将失败的任务重新分配

5. Hadoop组成

   - MapReduce（计算）
   - Yarn（资源调度）
   - HDFS（数据存储）
   - Common（辅助工具）

## HDFS架构概述

- Hadoop Distributed File System，简称 HDFS，是一个分布式文件系统
- HDFS架构概述
  1. NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等
  2. DataNode（dn）：在本地文件系统存储文件快数据，以及块数据的校验和
  3. Secondary NameNode（2nn）：每隔一段时间对NameNode元数据备份

## YARN架构概述

- Yet Another Resource Negotiator 简称YARN，另一种资源协调者，是Hadoop的资源管理器
- YARN架构概述
  1. ResourceManager（RM）：整个集群资源（内存、CPU等）的老大
  2. NodeManager（NM）：单个节点服务器资源老大
  3. ApplicationMaster（AM）：单个任务运行的老大
  4. Container：容器，相当一台独立的服务器，里面封装了任务运行所需要的资源，如内存、CPU、磁盘、网络等
     - 说明1：客户端可以有多个
     - 说明2：集群上可以运行多个ApplicationMaster
     - 说明3：每个NodeManager上可以有个Container

## MapReduce架构概述

MapReduce将计算过程分为两个阶段：Map和Reduce

1. Map阶段并行处理输入数据
2. Reduce阶段对Map结果进行汇总

## 大数据生态体系

1. Sqoop：Sqoop是一款开源的工具，主要用于在Hadoop、HIve与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如：MySQL，Oracle等）中的数据导进到Hadoop的HDFS中，也可以将HDFS中的数据导进到关系型数据库中
2. Flume：Flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据
3. Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统
4. Spark：Spark是当前最流行的开源大数据内存计算框架。
5. Flink：Flink是当前最流行的开源大数据内存计算框架
6. Oozie：Oozie是一个管理Hadoop作业（job）的工作流程调度管理系统
7. Hbase：HBase是一个分布式的、面向列的开源数据库
8. Hive：Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行
9. ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等

# Hadoop运行环境搭建

## 搭建模板机

1. 虚拟机网络IP地址修改

   - 修改网络IP地址为静态IP地址，避免地址经常变化，从而方便节点服务器间的互相通信

   ~~~sh
   vim /etc/sysconfig/network-seripts/ifcfg-ens33
   ~~~

   ~~~
   TYPE="Ethernet"    #网络类型（通常是Ethemet）
   PROXY_METHOD="none"
   BROWSER_ONLY="no"
   BOOTPROTO="static"   #IP的配置方法[none|static|bootp|dhcp]（引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议）
   DEFROUTE="yes"
   IPV4_FAILURE_FATAL="no"
   IPV6INIT="yes"
   IPV6_AUTOCONF="yes"
   IPV6_DEFROUTE="yes"
   IPV6_FAILURE_FATAL="no"
   IPV6_ADDR_GEN_MODE="stable-privacy"
   NAME="ens33"   
   UUID="e83804c1-3257-4584-81bb-660665ac22f6"   #随机id
   DEVICE="ens33"   #接口名（设备,网卡）
   ONBOOT="yes"   #系统启动的时候网络接口是否有效（yes/no）
   #IP地址
   IPADDR=192.168.10.100  
   #网关  
   GATEWAY=192.168.10.2      
   #域名解析器
   DNS1=192.168.10.2
   ~~~

   ~~~sh
   systemctl restart network #重启网络服务
   ~~~

2. 修改主机名
   - 修改主机名

~~~
vim /etc/hostname
hadoop100
~~~

- 配置Linux克隆机主机名称映射hosts文件，打开/etc/hosts

~~~
192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
~~~

3. 通过yum安装 epel-release

   - 注：Extra Package for Enterprise Linux是为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux

   ~~~sh
   yum install -y epel-release
   ~~~

4. Linux安装的是最小系统版，还需要安装如下工具

~~~
yum install -y net-tools

yum install -y vim
~~~

5. 关闭防火墙开机自启

~~~
stop firewalld

disable firewalld.service
~~~

6. 创建用户

~~~
useradd sry
passwd sry
~~~

7. 配置sry用户具有root权限

~~~
VIM /etc/sudoers
~~~

- 修改/etc/sudoers文件，在%wheel这行下面添加一行

~~~
## Allows people in group wheel to run all commands
%wheel  ALL=(ALL)       ALL
sry   ALL=(ALL)     NOPASSWD:ALL
~~~

8. 在/opt目录下创建文件夹

~~~
mkdir /opt/module
mkdir /opt/software

chown 777 /opt/module
chown 777 /opt/software
~~~

9. 卸载自带的jdk

~~~sh
rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps 
~~~

- rpm -qa：查询所安装的所有rpm软件包
- grep -i：忽略大小写
- xargs -n1：表示每次只传递一个参数
- rpm -e –nodeps：强制卸载软件

## 克隆虚拟机

1. 利用模板机hadoop100，克隆三台虚拟机：hadoop102 hadoop103 hadoop104
2. 修改克隆机IP，以下以hadoop102举例说明

~~~
vim /etc/sysconfig/network-scripts/ifcfg-ens33
~~~

~~~
DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.10.102
PREFIX=24
GATEWAY=192.168.10.2
DNS1=192.168.10.2
~~~

3. 修改克隆机主机名，以下以hadoop102举例说明

~~~
vim /etc/hostname
hadoop102
~~~

- 配置Linux克隆机主机名称映射hosts文件，打开/etc/hosts

~~~
vim /etc/hosts
~~~

~~~
192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
~~~

## 安装jdk

1. 解压JDK到/opt/module目录下

~~~
tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
~~~

2. 配置JDK环境变量

~~~
sudo vim /etc/profile.d/my_env.sh
~~~

~~~
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
~~~

3. source一下/etc/profile文件，让新的环境变量PATH生效

~~~
source /etc/profile
~~~

4. 测试JDK是否安装成功

~~~
java -version
~~~

## 安装hadoop

1. 解压安装文件到/opt/module下面

~~~
tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/
~~~

2. 将Hadoop添加到环境变量

~~~
sudo vim /etc/profile.d/my_env.sh
~~~

- 在my_env.sh文件末尾添加如下内容

~~~
#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
~~~

3. 让修改后的文件生效

~~~
source /etc/profile
~~~

4. 测试是否安装成功

~~~
hadoop version
~~~

## 编写分发脚本

1. 编写集群分发脚本 xsync

   1. scp 定义

      - scp可以实现服务器与服务器之间的数据拷贝（from server1 to server2）
      - 基本语法
      - scp -r -\$pdir/\$fname \$user@\$host:\$pdir/\$fname

   2. rsync 远程同步工具

      - rsync 主要用于备份和镜像。具有速度快、避免复制相同和支持符号链接的优点

      - rsync 和 scp 区别：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更新。scp是把所有文件都复制过去

      - 基本语法

      - rsync -av \$pdir/\$fname \$user@\$host:\$pdir/\$fname

      - | 选项 | 功能         |
        | ---- | ------------ |
        | -a   | 归档拷贝     |
        | -v   | 显示复制过程 |

   3. xsync 集群分发脚本

      1. 家目录下创建文件：xsync
      2. 编写脚本

      ~~~sh
      #!/bin/bash
      
      #1. 判断参数个数
      if [ $# -lt 1 ]
      then
          echo Not Enough Arguement!
          exit;
      fi
      
      #2. 遍历集群所有机器
      for host in hadoop102 hadoop103 hadoop104
      do
          echo ====================  $host  ====================
          #3. 遍历所有目录，挨个发送
      
          for file in $@
          do
              #4. 判断文件是否存在
              if [ -e $file ]
                  then
                      #5. 获取父目录
                      pdir=$(cd -P $(dirname $file); pwd)
      
                      #6. 获取当前文件的名称
                      fname=$(basename $file)
                      ssh $host "mkdir -p $pdir"
                      rsync -av $pdir/$fname $host:$pdir
                  else
                      echo $file does not exists!
              fi
          done
      done
      
      ~~~

## SSH无密登录配置

1. 配置ssh

   1. 基本语法

      - ssh \$host

   2. 无密钥配置

      1. 免密登录原理

         1. A 服务器 通过 ssh-key-gen 生成密钥对，分别是公钥(A)和私钥(A)
         2. 拷贝公钥A到B服务器，对公钥A授权 key Authorized_keys
         3. A服务器 ssh 访问B服务器 （数据用私钥A加密）
         4. B服务器 接收到数据后，去授权 key中 查找A的公钥，并解密数据
         5. 采用 A公钥加密的数据返回给服务器A

      2. 生成公钥和私钥

         1. 生成公钥和私钥路径：

         ~~~sh
         pwd
         /home/sry/.ssh
         ~~~

         2. 生成公钥和私钥，按两下回车，会生成两个文件
            - id_rsa （私钥）
            - id_rsa.pub （公钥）

         ~~~
         ssh-keygen -t rsa
         ~~~

         3. 将公钥拷贝到要免密登陆的目标机器上

         ~~~
         ssh-copy-id hadoop102
         ssh-copy-id hadoop103
         ssh-copy-id hadoop104
         ~~~

      3. .ssh 文件夹下(~/.ssh)的文件功能解释

      | 文件名          | 功能                                    |
      | --------------- | --------------------------------------- |
      | known_hosts     | 记录ssh访问过计算机的公钥(public  keys) |
      | id_rsa          | 生成的私钥                              |
      | id_rsa.pub      | 生成的公钥                              |
      | authorized_keys | 存放授权过的无密登录服务器公钥          |

## 集群部署规划

1. 集群部署规划

   - 注意：

     - NameNode 和 SecondaryNameNode 不要安装在同一台服务器
     - ResourceManager 也很消耗内存，不要和 NameNode、SecondaryNameNode 配置在同一台机器上

     |      | hadoop102              | hadoop103                        | hadoop104                       |
     | ---- | ---------------------- | -------------------------------- | ------------------------------- |
     | HDFS | NameNode<br />DataNode | DataNode                         | SecondaryNameNode<br />DataNode |
     | YARN | NodeManager            | ResourceManager<br />NodeManager | NodeManager                     |

2. 配置文件说明

   - Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值

   1. 默认配置文件

   | 默认文件           | 文件存放在Hadoop的jar包中的位置                           |
   | ------------------ | --------------------------------------------------------- |
   | core-defalut.xml   | hadoop-common-3.1.3.ar/core-default.xml                   |
   | hdfs-default.xml   | hadoop-hdfs-3.1.3.jar/hdfs-default.xml                    |
   | yarn-default.xml   | hadoop-yarn-common-3.1.3.jar/yarn-default.xml             |
   | mapred-default.xml | hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml |

   2. 自定义配置文件

   - core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml 四个配置文件存放在 \$HADOOP_HOME/etc/hadoop 这个路径上，用户可以根据项目需求重新进行修改配置

3. 配置集群

   1. 核心配置文件

      1. 配置 core-site.xml

      ~~~
      cd $HADOOP_HOME/etc/hadoop
      vim core-stie.xml
      ~~~

      ~~~xml
      <?xml version="1.0" encoding="UTF-8"?>
      <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
      
      <configuration>
          <!-- 指定NameNode的地址 -->
          <property>
              <name>fs.defaultFS</name>
              <value>hdfs://hadoop102:8020</value>
          </property>
      
          <!-- 指定hadoop数据的存储目录 -->
          <property>
              <name>hadoop.tmp.dir</name>
              <value>/opt/module/hadoop-3.1.3/data</value>
          </property>
      
          <!-- 配置HDFS网页登录使用的静态用户为atguigu -->
          <property>
              <name>hadoop.http.staticuser.user</name>
              <value>atguigu</value>
          </property>
      </configuration>
      
      ~~~

   2. HDFS 配置文件

   ~~~
   vim hdfs-site.xml
   ~~~

   ~~~
   <?xml version="1.0" encoding="UTF-8"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   
   <configuration>
   	<!-- nn web端访问地址-->
   	<property>
           <name>dfs.namenode.http-address</name>
           <value>hadoop102:9870</value>
       </property>
   	<!-- 2nn web端访问地址-->
       <property>
           <name>dfs.namenode.secondary.http-address</name>
           <value>hadoop104:9868</value>
       </property>
   </configuration>
   
   ~~~

   3. YARN 配置文件

   ~~~
   vim yarn-site.xml
   ~~~

   ~~~
   <?xml version="1.0" encoding="UTF-8"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   
   <configuration>
       <!-- 指定MR走shuffle -->
       <property>
           <name>yarn.nodemanager.aux-services</name>
           <value>mapreduce_shuffle</value>
       </property>
   
       <!-- 指定ResourceManager的地址-->
       <property>
           <name>yarn.resourcemanager.hostname</name>
           <value>hadoop103</value>
       </property>
   
       <!--3.2以后不用配这个变量 -->
       <!-- 环境变量的继承 -->
       <property>
           <name>yarn.nodemanager.env-whitelist</name>
           <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
       </property>
   </configuration>
   
   ~~~

   4. MapReduce 配置文件

   ~~~
   vim mapred-site.xml
   ~~~

   ~~~
   <?xml version="1.0" encoding="UTF-8"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   
   <configuration>
   	<!-- 指定MapReduce程序运行在Yarn上 -->
       <property>
           <name>mapreduce.framework.name</name>
           <value>yarn</value>
       </property>
   </configuration>
   
   ~~~

4. 在集群上分发配置好的 Hadoop 配置文件

~~~sh
xsync /opt/module/hadoop-3.1.3/etc/hadoop/
~~~

5. 查看文件分发情况

## 群起集群

1. 配置workers

~~~
vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
~~~

~~~
hadoop102
hadoop103
hadoop104
~~~

~~~
xsync /opt/module/hadoop-3.1.3/etc/hadoop/workers
~~~

2. 启动集群

   1. 格式化NameNode
      - 如果集群是第一次启动，需要在hadoop102 节点格式化 NameNode (注意：格式化NameNode，会产生新的集群id，导致NameNode 和 DateNode 的集群 id 不一致，集群找不到以往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化)

   ~~~
   hdfs namenode -format
   ~~~

   2. 启动 HDFS

   ~~~
   sbin/start-dfs.sh
   ~~~

   3. 在配置的ResourceManager的节点（hadoop103）启动YARN

   ~~~
   sbin/start-yarn.sh
   ~~~

   4. Web端查看HDFS的NameNode
      - http://hadoop102:9870/
      - 查看HDFS上存储的数据信息
   5. Web端查看YARN的ResourceManager
      - http://hadoop103:8088
      - 查看YARN上运行的Job信息

## 配置历史服务器

- 为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：

1. 配置 mapred-site.xml

~~~
vim mapred-site.xml
~~~

~~~xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>

~~~

2. 分发配置

~~~sh
xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml
~~~

3. 在hadoop102 启动历史服务器

~~~
mapred --daemon start historyserver
~~~

4. 查看历史服务器是否启动

~~~
jps
~~~

5. 查看 JobHistory
   - http://hadoop102:19888/jobhistory

## 配置日志的聚集

- 日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上
- 日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试
- 注意：开启日志聚集功能，需要重新启动 NodeManager、ResourceManager 和 HistoryServer

1. 配置 yarn-site.xml

~~~
vim yarn-site.xml
~~~

~~~xml
<!-- 开启日志聚集功能 -->
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
<!-- 设置日志聚集服务器地址 -->
<property>  
    <name>yarn.log.server.url</name>  
    <value>http://hadoop102:19888/jobhistory/logs</value>
</property>
<!-- 设置日志保留时间为7天 -->
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>

~~~

2. 分发配置

~~~
xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml
~~~

3. 关闭 NodeManager、ResourceManager 和 HistoryServer

~~~
sbin/stop-yarn.sh
mapred --daemon stop historyserver
~~~

4. 启动NodeManager、ResourceManager 和 HistoryServer

~~~
start-yarn.sh
mapred --daemon start historyserver
~~~

5. 查看日志
   - http://hadoop102:19888/jobhistory

## 集群启动/停止方式总结

1. 各个模块分开启动/停止（配置 ssh 是前提）

   1. 整体启动/停止 HDFS

   ~~~
   start-dfs.sh/stop-dfs.sh
   ~~~

   2. 整体启动/停止YARN

   ~~~
   start-yarn.sh/stop-yarn/sh
   ~~~

2. 各个服务组件逐一启动/停止

   1. 分别启动/停止HDFS组件

   ~~~
   hdfs --daemon start/stop namenode/datanode/secondarynamenode
   ~~~

   2. 启动/停止 YARN

   ~~~
   yarn --daemon start/stop resourcemanager/nodemanager
   ~~~

## 编写Hadoop集群常用脚本

1. Hadoop 集群启停脚本（包含 HDFS，Yarn，Historyserver）：myhadoop.sh

~~~
vim myhadoop.sh
~~~

~~~
#!/bin/bash

if [ $# -lt 1 ]
then
    echo "No Args Input..."
    exit ;
fi

case $1 in
"start")
        echo " =================== 启动 hadoop集群 ==================="

        echo " --------------- 启动 hdfs ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh"
        echo " --------------- 启动 yarn ---------------"
        ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"
        echo " --------------- 启动 historyserver ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;
"stop")
        echo " =================== 关闭 hadoop集群 ==================="

        echo " --------------- 关闭 historyserver ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
        echo " --------------- 关闭 yarn ---------------"
        ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
        echo " --------------- 关闭 hdfs ---------------"
        ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
;;
*)
    echo "Input Args Error..."
;;
esac

~~~

2. 查看三台服务器 Java 进程脚本：jpsall

~~~
vim jpsall
~~~

~~~
#!/bin/bash

for host in hadoop102 hadoop103 hadoop104
do
        echo =============== $host ===============
        ssh $host jps 
done
~~~

## 常用端口号说明

| 端口名称                   | Hadoop3.x          |
| -------------------------- | ------------------ |
| NameNode 内部通信端口      | 8020 / 9000 / 9820 |
| NameNode HTTP UI           | 9870               |
| MapReduce 查看执行任务端口 | 8088               |
| 历史服务器通信端口         | 19888              |

## 集群时间同步

- 如果服务器在公网环境，可以不采用集群时间同步，因为服务器会定期和公网时间进行校准
- 如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步

1. 查看所有节点 ntpd 服务状态和开机自启动状态

~~~
sudo systemctl status ntpd
sudo systemctl start ntpd
sudo systemctl is-enabled ntpd
~~~

2. 修改hadoop102的ntp.conf配置文件

~~~
sudo vim /etc/ntp.conf
~~~

~~~sh
#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap 
##修改为
restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap 

server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst
##为
#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst

server 127.127.1.0
fudge 127.127.1.0 stratum 10
~~~

3. 修改hadoop102的/etc/sysconfig/ntpd 文件

~~~
 sudo vim /etc/sysconfig/ntpd
~~~

~~~
##让硬件时间与系统时间一起同步
SYNC_HWCLOCK=yes
~~~

4. 重新启动ntpd服务

~~~
sudo systemctl start ntpd
~~~

5. 设置ntpd服务开机启动

~~~
sudo systemctl enable ntpd
~~~

6. 其他机器配置（必须root服务）

   1. 关闭所有节点上ntp服务和自启动

   ~~~
   sudo systemctl stop ntpd
   sudo systemctl disable ntpd
   sudo systemctl stop ntpd
   sudo systemctl disable ntpd
   ~~~

   2. 在其他机器配置1分钟与时间服务器同步一次

   ~~~
   sudo crontab -e
   ~~~

   ~~~
   */1 * * * * /usr/sbin/ntpdate hadoop102
   ~~~

# Hadoop目录结构

1. 重要目录
   - bin目录：存放对Hadoop相关服务(hdfs,yarn,mapred)进行操作的脚本
   - etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件
   - lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）
   - sbin目录：存放启动或停止Hadoop相关服务的脚本
   - share目录：存放Hadoop的依赖jar包，文档、和官方案例
2. Hadoop运行模式
   1. Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式
      - 本地模式：单机运行，数据存储在linux本地
      - 伪分布式模式：单机运行，但是具备Hadoop集群的所有功能，一台服务器模拟一个分布式的环境。
      - 完全分布式模式：多台服务器组成分布式环境。
