# `Kafka` 生产者

## 生产者消息发送流程

### 发送原理

- 在消息发送的过程中，涉及到了两个线程——`main`线程和`Sender`线程。在`main`线程中创建了一个双端队列`RecordAccmulator`。`main`线程将消息发送给`RecordAccumulator`,`Sender`线程不断从`RecordAccumulator`中拉取消息发送到`Kafka Broker`

## 生产者重要参数列表

| 参数名称                                   | 描述                                                         |
| ------------------------------------------ | ------------------------------------------------------------ |
| `bootstrap.servers`                        | 生产者连接集群所需的 `broker`  地址清单。 例如 <br/>`hadoop102:9092,hadoop103:9092,hadoop104:9092`，可以设置 1  个或者多个，中间用逗号隔开。注意这里并非需要所有的 `broker`  地址，因为生产者从给定的 `broker`<br/>里查找到其他 `broker` 信息。 |
| `key.serializer`<br/>和 `value.serializer` | 指定发送消息的 `key` 和 `value` 的序列化类型。一定要写全类名。 |
| `buffer.memory`                            | `RecordAccumulator` 缓冲区总大小，默认 `32m`。               |
| `batch.size`                               | 缓冲区一批数据最大值，默认 `16k`。适当增加该值，可<br/>以提高吞吐量，但是如果该值设置太大，会导致数据<br/>传输延迟增加。 |
| `linger.ms`                                | 如果数据迟迟未达到 `batch.size`，``sender` 等待 `linger.time`<br/>之后就会发送数据。单位 `ms`，默认值是 `0ms`，表示没有延迟。生产环境建议该值大小为 `5-100ms` 之间。 |
| `acks`                                     | 0：生产者发送过来的数据，不需要等数据落盘应答。<br/>1：生产者发送过来的数据，Leader 收到数据后应答。<br/>-1（all）：生产者发送过来的数据，`Leader`和 `isr`  队列里面的所有节点收齐数据后应答。默认值是-1，-1  和 `all` 是等价的。 |
| `max.in.flight.requests.per.connection`    | 允许最多没有返回 `ack` 的次数，默认为 5，开启幂等性<br/>要保证该值是 1-5 的数字。 |
| `retries`                                  | 当消息发送出现错误的时候，系统会重发消息。`retries`<br/>表示重试次数。默认是 `int` 最大值，2147483647。  如果设置了重试，还想保证消息的有序性，需要设置<br/>`MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1`<br/>否则在重试此失败消息的时候，其他的消息可能发送<br/>成功了。 |
| `retry.backoff.ms`                         | 两次重试之间的时间间隔，默认是<br/>`100 m s`                 |
| `enable.idempotence`                       | 是否开启<br/>幂等性 默认 `true` ，开启 幂等性 。             |
| `compression.type`                         | 生产者发送的所有数据的压缩方式。<br/>默认是 `none` ，也就是不压缩。<br/>支持压缩类型 `none 、 gzip 、 snappy 、 lz4 和 zstd `。 |

## 异步发送`API`

### 普通异步发送

1. 导入依赖

   ~~~
   <dependencies>
   	<dependency>
   		<groupId>org.apache.kafka</groupId>
   		<artifactId>kafka-clients</artifactId>
   		<version>3.0.0</version>
   	</dependency>
   </dependencies>
   ~~~

2. 编写不带回调函数的`API` 代码

   ~~~java
   public class CustomProducer {
   
       public static void main(String[] args) {
           // 0 配置
           Properties properties = new Properties();
   
           // 连接集群
           properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
           properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
           properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
   
   
           //1.创建 kafka 生产者对象
           // hello
           KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
   
           //2 发送数据
           for (int i = 0; i < 5; i++) {
               kafkaProducer.send(new ProducerRecord("first", "atguigu" + i));
           }
   
           //3 关闭资源
           kafkaProducer.close();
       }
   }
   ~~~

### 带回调函数的 异步发送

- 回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，分别是元数据信息（`RecordMetadata`）和异常信息（`Exception`），如果 `Exception` 为 null，说明消息发送成功，如果`Exception`不为 null，说明消息发送失败。
- 注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。

1. 编写代码

   ~~~
   public class CustomProducerCallback {
   
       public static void main(String[] args) {
   
           // 0 配置
           Properties properties = new Properties();
   
           // 连接集群
           properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
           properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
           properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
   
   
           //1.创建 kafka 生产者对象
           // hello
           KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
   
           //2 发送数据
           for (int i = 0; i < 5; i++) {
               kafkaProducer.send(new ProducerRecord("first", "atguigu" + i), new Callback() {
                   @Override
                   public void onCompletion(RecordMetadata metadata, Exception exception) {
                       if (exception == null) {
                           System.out.println("主题：" + metadata.topic() + " 分区：" + metadata.partition());
                       }
                   }
               });
           }
   
           //3 关闭资源
           kafkaProducer.close();
   
       }
   }
   ~~~

### 同步发送`API`

- 只需在异步发送的基础上，再调用一下`get()`方法即可

  ~~~
  public class CustomProducerSync {
  
      public static void main(String[] args) throws ExecutionException, InterruptedException {
  
          // 0 配置
          Properties properties = new Properties();
  
          // 连接集群
          properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
          properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
          properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
  
  
          //1.创建 kafka 生产者对象
          // hello
          KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
  
          //2 发送数据
          for (int i = 0; i < 5; i++) {
              kafkaProducer.send(new ProducerRecord("first", "atguigu" + i), new Callback() {
                  @Override
                  public void onCompletion(RecordMetadata metadata, Exception exception) {
                      if (exception == null) {
                          System.out.println("主题：" + metadata.topic() + " 分区：" + metadata.partition());
                      }
                  }
              }).get();
          }
  
          //3 关闭资源
          kafkaProducer.close();
  
      }
  
  }
  
  ~~~

## 生产者分区

### 分区好处

1. 便于合理使用存储资源，每个`Partition`在一个`Broker`上存储，可以把海量的数据按照分区切割成一块一块数组存储在多台`Broker`上。合理控制分区的任务，可以实现负载均衡的效果
2. 提高并行度，生产者可以以分区为单位发送数据；消费者可以以分区为单位进行消费数据

### 生产者发送消息的分区策略

1. 默认的分区器`DefaultPartitioner`

   - 在`IDEA`中`ctrl+n`，全局查找`DefaultPartitioner`

2. 在`IDEA`中全局查找(`ctrl+n`)`ProducerRecord`类，在类中可以看到三个大类构造方法

   1. 指明`partition`的情况下，直接将指明的值作为`partition`值；例如`partition=0`,所有数据写入分区0

   2. 没有指明`partition`值但有`key`的情况下，将`key`的`hash`值与`topic`的`partition`数进行取余得到`partition`的值

   3. 即没有`partition`值又没有key值的情况下，`Kafka`采用`Sticky Partition`（黏性分区器），会随机选择一个分区，并尽可能一直使用该分区，待该分区的`batch`已满或者已完成，`Kafka`再随机一个分区进行使用（和上一次的分区不同）

      例如：第一次随机选择0号分区，等0号分区当前批次满了（默认16k）或者`linger.ms`设置的时间到，`Kafka`再随机一个分区进行使用(如果还是0会继续随机)

- 案例一

  - 将数据发往指定 `partition`的情况下

  ~~~
  public class CustomProducerCallbackPartitions {
  
      public static void main(String[] args) throws InterruptedException {
  
          // 0 配置
          Properties properties = new Properties();
  
          // 连接集群
          properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
          properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
          properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
  
          //关联自定义分区其
          properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,"com.atguigu.kafka.producer.MyPartitioner");
  
          //1.创建 kafka 生产者对象
          // hello
          KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
  
          //2 发送数据
          for (int i = 0; i < 50; i++) {
              //指定数据发送到 1 号分区，key 为空（IDEA 中 ctrl + p 查看参数）
              kafkaProducer.send(new ProducerRecord("first",1,"","atguigu" + i), new Callback() {
                  @Override
                  public void onCompletion(RecordMetadata metadata, Exception exception) {
                      if (exception == null) {
                          System.out.println("主题：" + metadata.topic() + " 分区：" + metadata.partition());
                      }
                  }
              });
  
              Thread.sleep(2);
          }
  
          //3 关闭资源
          kafkaProducer.close();
  
      }
  }
  ~~~

- 案例二

  - 没有指明 `partition`值但有`key`的情况下，将`key`的`hash`值与`topic`的`partition`数进行取余得到`partition`值

  ~~~
  public class CustomProducerCallbackPartitions {
  
      public static void main(String[] args) throws InterruptedException {
  
          // 0 配置
          Properties properties = new Properties();
  
          // 连接集群
          properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
          properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
          properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
  
          //关联自定义分区其
          properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,"com.atguigu.kafka.producer.MyPartitioner");
  
          //1.创建 kafka 生产者对象
          // hello
          KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
  
          //2 发送数据
          for (int i = 0; i < 50; i++) {
              //依次指定 key 值为 a,b,f,数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0
              kafkaProducer.send(new ProducerRecord("first","a","atguigu" + i), new Callback() {
                  @Override
                  public void onCompletion(RecordMetadata metadata, Exception exception) {
                      if (exception == null) {
                          System.out.println("主题：" + metadata.topic() + " 分区：" + metadata.partition());
                      }
                  }
              });
  
              Thread.sleep(2);
          }
  
          //3 关闭资源
          kafkaProducer.close();
  
      }
  }
  ~~~

### 自定义分区器

1. 定义类实现 `Partition`接口

2. 重写 `partition()`方法

   ~~~
   public class MyPartitioner implements Partitioner {
       @Override
       public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
   
           //获取数据 atguigu hello
           String msgValues = value.toString();
   
           int partition;
           if(msgValues.contains("atguigu")){
               partition = 0;
           } else {
               partition = 1;
           }
           return partition;
       }
   
       @Override
       public void close() {
   
       }
   
       @Override
       public void configure(Map<String, ?> configs) {
   
       }
   }
   
   ~~~

3. 使用分区器的方法，在生产者的配置中添加分区器参数

   ~~~
   public class CustomProducerCallbackPartitions {
   
       public static void main(String[] args) throws InterruptedException {
   
           // 0 配置
           Properties properties = new Properties();
   
           // 连接集群
           properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
           properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
           properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
   
           //关联自定义分区其
           properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,"com.atguigu.kafka.producer.MyPartitioner");
   
           //1.创建 kafka 生产者对象
           // hello
           KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
   
           //2 发送数据
           for (int i = 0; i < 50; i++) {
               kafkaProducer.send(new ProducerRecord("first","atguigu" + i), new Callback() {
                   @Override
                   public void onCompletion(RecordMetadata metadata, Exception exception) {
                       if (exception == null) {
                           System.out.println("主题：" + metadata.topic() + " 分区：" + metadata.partition());
                       }
                   }
               });
   
               Thread.sleep(2);
           }
   
           //3 关闭资源
           kafkaProducer.close();
   
       }
   }
   ~~~

## 生产经验

### 生产者如何提高吞吐量

- `batch.size`：批次大小，默认`16k`
- `linger.ms`：等待时间，修改为`5-100ms`
- `compression.type`：压缩`snappy`
- `RecordAccumulator`：缓冲区大小，修改为`64m`

### 数据可靠性

1. `ack`应答原理

   - 0：生产者发送过来的数据，不需要等数据落盘应答
   - 1：生产者发送过来的数据，`Leader`收到数据后应答
   - -1(`all`)：生产者发送过来的数据，`Leader`和`ISR`队列里面的所有节点收齐数据后应答
     - `Replicas`队列里面有一个`Follower`迟迟不能与`Leader`进行同步，这种情况如何解决？
       - `Leader`维护了一个动态的`in-sync replica set(ISR)`，意为和`Leader`保持同步的`Follower+Leader`集合(`leader`：0，`isr`：0，1，2)
       - 如果`Follower`长时间未向`Leader`发送通信请求或同步数据，则该`Follower`将被踢出`ISR`。该时间阀值由`replica.lag.time.max.ms`参数设定，默认`30s`。
       - 这样，就不用等待长期联系不上或者已经故障的节点

2. 数据可靠性分析：

   - 如果分区副本设置为 1 个，或者`ISR`里应答的最小副本数量(`min.insync.replicas`默认为 1)设置为 1 ，和 `ack`=1的效果是一样的，仍然有丢数的风险(`leader`：0，`isr`：0)
   - 数据完全可靠条件 = `ACK`级别设置为 -1 + 分区副本大于等于 2 + `ISR`里应答的最小副本数量大于等于 2

3. 可靠性总结

   - `ack` =  0，生产者发送过来数据就不管了，可靠性差，效率高
   - `ack` = 1， 生产者发送过来数据 `Leader`应答，可靠性中等，效率中等
   - `ack` = -1，生产者发送过来数据`Leader`和`ISR`队列里面所有`Follower`应答，可靠性高，效率低
   - 在生产环境中，`ack` = 0 很少使用；ack = 1，一般用于传输普通日志，允许丢个别数据；acks = -1，一般用于传输和钱相关的数据，对可靠性要求比较高的场景

4. 代码

   ~~~
   public class CustomProducerParameters {
   
       public static void main(String[] args) {
   
           Properties properties = new Properties();
   
           properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
   
           properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
   
           properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
           
           // 设置 ack s
   	   properties.put( ProducerConfig.ACKS_CONFIG , "all");
   	
   	   // 重试次数 retries ，默认是 int 最大值， 2147483647
          properties.put( ProducerConfig.RETRIES_CONFIG ,3);
   
           //1 创建生产者
           KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
   
           //
   
           for(int i = 0;i < 5;i++){
               kafkaProducer.send(new ProducerRecord<>("first","atguigu"+i));
           }
   
           kafkaProducer.close();
       }
   }
   ~~~

   

### 数据重复分析

#### 数据传递语义

- 至少一次（`At Least Once`） = `ACK`级别设置为 -1 + 分区副本大于等于 2 + `ISR`里应答的最小副本数量大于等于 2
- 至多一次（`At Most Once`) = `ACK`级别设置为 0 
- 总结：
  - `At Least Once`可以保证数据不丢失，但是不能保证数据不重复
  - `At Most Once`可以保证数据不重复，但是不能保证数据不丢失
- 精确一次(`Exactly Once`)：对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失
  - `Kafka 0.11`版本以后，引入了一项重大特性：幂等性和事务

#### 幂等性

- 幂等性是指`Producer`不论向`Broker`发送多少次重复数据，`Broker`端都只会持久化一条，保证了不重复

- 精确一次(`Exactly Once`) = 幂等性 + 至少一次 (ack = -1 + 分区副本数 >= 2 + `ISR`最小副本数量 >= 2 )

- 重复数据的判断标准：具有 <`PID`,`Partition`,`SeqNumber`>相同主键的消息提交时，`Broker`只会持久化一条。其中`PID`是`Kafka`每次重启都会分配一个新的；`Partition`表示分区号；`Sequence Number`是单调自增的
- 所以幂等性只能保证的是在单分区单会话内不重复

1. 如何使用幂等性
   - 开启参数 `enable.idempotence`默认为`true`,`false`关闭

#### 生产者事务

- 说明：开启事务，必须开启幂等性
- `transaction_state`-分区-Leader：存储事务信息的特殊主题
  - 默认有50个分区，每个分区负责一部分事务。事务划分是根据`transactional.id`的`hashcode`值%50,计算出该事务属于哪个分区。该分区`Leader`副本所在的`broker`节点即为这个`transactional.id`对应的`Transaction Coordinator`节点
- 事务流程
  1. `Kafka Producer`向 `Transaction Coordinator`请求`producer id`(幂等性需要)
  2. `Transaction Coordinator` 返回 `producer id`给`Kafka Producer`
  3. `Kafka Producer`发送消息到`TopicA`
  4. `Kafka Producer`向`Transaction Coordinator`发送`commit`请求
  5.  `Transaction Coordinator`向`transaction_state`发送持久化`commit`请求
  6.  `Transaction Coordinator`返回成功给`Kafka Producer`
  7. `Transaction Coordinator`向`TopicA-Partition()Leader`后台发送`commit`请求
  8. `TopicA-Partition()Leader`返回给`Transaction Coordinator`成功
  9. `Transaction Coordinator`向`transaction_state`持久化事务成功信息
- tips：
  - `Producer`在使用事务功能钱，1必须先自定义一个唯一的`transactional.id`。有了`transactional.id`，即使客户端挂掉了，它重启后也能继续处理未完成的事物

- 代码

  ~~~
  public class CustomProducerTransactions {
  
      public static void main(String[] args) {
          // 0 配置
          Properties properties = new Properties();
  
          // 连接集群
          properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "hadoop102:9092,hadoop103:9092");
          properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
          properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
  
          //指定事务id
          properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,"transaction_id_01");
  
  
          //1.创建 kafka 生产者对象
          // hello
          KafkaProducer<String, String> kafkaProducer = new KafkaProducer<>(properties);
  
          kafkaProducer.initTransactions();
  
          kafkaProducer.beginTransaction();
  
  
          try {
              //2 发送数据
              for (int i = 0; i < 5; i++) {
                  kafkaProducer.send(new ProducerRecord("first", "atguigu" + i));
              }
  
              int i = 1 / 0;
  
              kafkaProducer.commitTransaction();
          }catch (Exception e){
              kafkaProducer.abortTransaction();
          }finally {
              //3 关闭资源
              kafkaProducer.close();
          }
      }
  }
  ~~~

#### 数据乱序

- 单分区内，有序
- 多分区，分区与分区间无序
- `kafka`在`1.x`及以后版本保证数据单分区有序
  1. 未开启幂等性
     - `max.in.flight.requests.per.connection`需要设置为1
  2. 开启幂等性
     - `max.in.flight.requests.per.connection`需要设置小于等于5
     - 原因说明：因为在`kafka1.x`以后，启用幂等后，`kafka`服务端会缓存`producer`发来的最近5个`request`的元数据，故无论如何，都可以保证最近5个`request`的数据都是有序的

